# ğŸš´ï¸ StravaScraper

**StravaScraper** es una herramienta desarrollada en Python que permite obtener informaciÃ³n pÃºblica de perfiles de atletas de Strava mediante *web scraping*. EstÃ¡ diseÃ±ada para ejecutarse como **API REST (FastAPI)** o desde la **lÃ­nea de comandos (CLI)**. AdemÃ¡s, estÃ¡ completamente contenedorizada con **Docker**.

---

## âœ¨ Funcionalidades

- ğŸ” Buscar usuarios por nombre  
- ğŸ§ Obtener perfil individual por ID  
- ğŸ“¦ Obtener mÃºltiples perfiles por lista de IDs  
- ğŸ“„ Exportar los resultados en formato JSON  
- ğŸŒ ExposiciÃ³n vÃ­a API REST o CLI  
- ğŸ³ Contenedorizado con Docker y compatible con Make  

---

## âš™ï¸ Requisitos

- Python 3.11+ (probado con 3.13.3)  
- Docker + Docker Compose  
- GNU Make (opcional para desarrollo mÃ¡s Ã¡gil)  
- Archivo `.env` con cookies de sesiÃ³n vÃ¡lidas  

---

## ğŸ” ConfiguraciÃ³n `.env`

```env
STRAVA_SESSION=tu_cookie_strava_session
STRAVA_REMEMBER_ID=tu_strava_remember_id
STRAVA_REMEMBER_TOKEN=tu_strava_remember_token

UVICORN_HOST=0.0.0.0
UVICORN_PORT=8000
```

---

## ğŸ³ Uso con Docker

### ğŸ”¨ Levantar la API

```bash
docker-compose up -d
```


### ğŸ’» Entrar al contenedor (para usar CLI manualmente)

```bash
docker exec -it strava_api bash
```

---

## âš™ï¸ Uso con Make (opcional)

```bash
make up                       # Inicia el contenedor con FastAPI
make down                    # Detiene el contenedor
make logs                    # Muestra los logs
make shell                   # Accede al contenedor con bash
make cli NAME=juan           # Ejecuta el CLI buscando por nombre
make cli IDS="123 456"       # Ejecuta el CLI buscando por IDs
make cli NAME=juan EXPORT=true  # Exporta a JSON
```

---

## ğŸ“¬ Ejemplos de uso vÃ­a API (curl)

### ğŸ” Buscar usuarios por nombre

```bash
curl --location 'http://127.0.0.1:8000/api/search/?name=juan'
```

### ğŸ‘¤ Obtener perfil por ID

```bash
curl --location 'http://127.0.0.1:8000/api/profile/45678'
```

### ğŸ“¦ Obtener perfiles por lista de IDs

```bash
curl --location 'http://127.0.0.1:8000/api/profiles' \
     --header 'Content-Type: application/json' \
     --data '{
       "user_ids": [30995, 36442011, 5952380]
     }'
```

### ğŸ“„ Exportar perfiles a JSON (por IDs)

```bash
curl --location 'http://127.0.0.1:8000/api/export/by-ids' \
--header 'Content-Type: application/json' \
--data '{
  "user_ids": [3098895, 36442011, 5952380]
}'
```

---

## ğŸ’» Uso por lÃ­nea de comandos (CLI)

```bash
# Obtener por nombre
python -m cli --name juan

# Obtener por IDs
python -m cli --ids 3098895 36442011

# Exportar a JSON
python -m cli --name juan --export
```

---

## ğŸ§ª InstalaciÃ³n local (sin Docker)

Desarrollar localmente sin usar contenedores Docker:

```bash
# Crea un entorno virtual
python -m venv .venv

# Activa el entorno
source .venv/bin/activate   # En Windows: .venv\Scripts\activate

# Instala las dependencias
pip install -r requirements.txt

# Ejecuta desde CLI
python -m cli --name juan
```

---

## ğŸ§  Decisiones tÃ©cnicas

- ğŸ” AutenticaciÃ³n por cookies capturadas desde una sesiÃ³n legÃ­tima en Strava.
- ğŸ§¼ Uso de `BeautifulSoup` para parsear HTML.
- âŸ² Scraper centralizado en `StravaScraper`, reutilizable vÃ­a API o CLI.
- ğŸ§± Estructura modular con `file_system` para rutas y exportaciÃ³n.
- ğŸ“‚ Sistema de archivos gestionado por `FileSystemManager` con soporte singleton.
- ğŸ“„ ExportaciÃ³n por defecto en `core/config/_data/users.json` o donde el desarrollador indique.

---

## ğŸ”§ Arquitectura del cliente HTTP

- âœ¨ Cliente desacoplado mediante inyecciÃ³n: `RequestsClient`.
- ğŸŒ Cabeceras realistas generadas con `browserforge`.
- ğŸ”§ MÃ©todos: `request_get`, `request_post`, `load_cookies`.
- ğŸ”Œ DiseÃ±o extensible a Playwright, Selenium, etc.

```python
from core.http_client.requests_client import RequestsClient
scraper = StravaScraper(RequestsClient())
```

---

## ğŸ“‚ Estructura del proyecto

```
.
â”œâ”€â”€ api/                 # FastAPI
â”œâ”€â”€ cli/                 # CLI ejecutable
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ engine/          # LÃ³gica de scraping
â”‚   â”œâ”€â”€ http_client/     # Cliente HTTP
â”‚   â”œâ”€â”€ file_system/     # Rutas, exportaciones
â”‚   â””â”€â”€ config/          # _data/users.json
â”œâ”€â”€ models.py            # DTO principal
â”œâ”€â”€ api_models.py        # Pydantic para FastAPI
â”œâ”€â”€ settings.py          # ConfiguraciÃ³n y logger
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ Makefile
```

---

## ğŸ‘¤ Autor

**Juan Daniel**  
Desarrollador backend | scraping & automatizaciÃ³n  
GitHub: [@JuanDiaz91](https://github.com/JuanDiaz91)

